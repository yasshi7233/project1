{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Smart Product Pricing Challenge - Data Exploration\n",
        "\n",
        "This notebook explores the training dataset and implements preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "train_df = pd.read_csv('../dataset/train.csv')\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Columns: {train_df.columns.tolist()}\")\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic data info\n",
        "print(\"Dataset Info:\")\n",
        "print(train_df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(train_df.isnull().sum())\n",
        "print(\"\\nPrice statistics:\")\n",
        "print(train_df['price'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price distribution\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.hist(train_df['price'], bins=50, alpha=0.7)\n",
        "plt.title('Price Distribution')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.hist(np.log1p(train_df['price']), bins=50, alpha=0.7)\n",
        "plt.title('Log Price Distribution')\n",
        "plt.xlabel('Log(Price + 1)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.boxplot(train_df['price'])\n",
        "plt.title('Price Box Plot')\n",
        "plt.ylabel('Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample catalog content analysis\n",
        "print(\"Sample catalog content:\")\n",
        "for i in range(3):\n",
        "    print(f\"\\nSample {i+1}:\")\n",
        "    print(train_df.iloc[i]['catalog_content'])\n",
        "    print(f\"Price: {train_df.iloc[i]['price']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text preprocessing functions\n",
        "def extract_ipq(text):\n",
        "    \"\"\"Extract Item Pack Quantity from text\"\"\"\n",
        "    # Look for patterns like \"Pack of 5\", \"5 Pack\", \"Quantity: 10\", etc.\n",
        "    patterns = [\n",
        "        r'pack of (\\d+)',\n",
        "        r'(\\d+) pack',\n",
        "        r'quantity[\\s:]+(\\d+)',\n",
        "        r'ipq[\\s:]+(\\d+)',\n",
        "        r'(\\d+)\\s*x\\s*(\\d+)',  # For cases like \"5 x 2\"\n",
        "    ]\n",
        "    \n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text.lower())\n",
        "        if match:\n",
        "            if len(match.groups()) == 2:  # For patterns like \"5 x 2\"\n",
        "                return int(match.group(1)) * int(match.group(2))\n",
        "            else:\n",
        "                return int(match.group(1))\n",
        "    \n",
        "    return 1  # Default to 1 if not found\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and preprocess text\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove special characters but keep spaces\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "    \n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "train_df['cleaned_text'] = train_df['catalog_content'].apply(clean_text)\n",
        "train_df['ipq'] = train_df['catalog_content'].apply(extract_ipq)\n",
        "\n",
        "print(\"IPQ extraction results:\")\n",
        "print(train_df['ipq'].value_counts().head(10))\n",
        "print(f\"\\nAverage IPQ: {train_df['ipq'].mean():.2f}\")\n",
        "print(f\"Max IPQ: {train_df['ipq'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text length analysis\n",
        "train_df['text_length'] = train_df['cleaned_text'].str.len()\n",
        "train_df['word_count'] = train_df['cleaned_text'].str.split().str.len()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(train_df['text_length'], train_df['price'], alpha=0.5)\n",
        "plt.title('Text Length vs Price')\n",
        "plt.xlabel('Text Length')\n",
        "plt.ylabel('Price')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(train_df['word_count'], train_df['price'], alpha=0.5)\n",
        "plt.title('Word Count vs Price')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "numeric_features = ['ipq', 'text_length', 'word_count', 'price']\n",
        "correlation_matrix = train_df[numeric_features].corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save preprocessed data\n",
        "train_df.to_csv('../dataset/train_preprocessed.csv', index=False)\n",
        "print(\"Preprocessed training data saved!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
